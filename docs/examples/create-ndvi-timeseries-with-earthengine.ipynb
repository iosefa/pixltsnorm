{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "416412b80677768d",
   "metadata": {},
   "source": [
    "# Creating NDVI Timeseries for Different Landsat Sensors using Google Earth Engine\n",
    "\n",
    "This notebook outlines how `pixltsnorm` can be used to create timeseries dataframes of NDVI at each pixel for three different landsat sensors using Google Earth Engine.\n",
    "\n",
    "First, let's import the base packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59e2a91d9b86f75c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T21:51:51.066950Z",
     "start_time": "2025-03-15T21:51:48.122197Z"
    }
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "import fiona\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd98bc7ba32f053a",
   "metadata": {},
   "source": [
    "Now, lets import the pixltsnorm modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c028edc74070751",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T21:52:10.250117Z",
     "start_time": "2025-03-15T21:52:09.901564Z"
    }
   },
   "outputs": [],
   "source": [
    "from pixltsnorm.earth_engine.landsat import cloudMaskL457, scale_factors, addNDVI, create_reduce_region_function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9666f2c99222eaff",
   "metadata": {},
   "source": [
    "First, let's ' set the dates for each sensor that we want and define the region of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2630d0671f342be6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T21:52:11.370849Z",
     "start_time": "2025-03-15T21:52:11.355251Z"
    }
   },
   "outputs": [],
   "source": [
    "start_date_l5 = '1985-01-01'\n",
    "end_date_l5 = '2012-04-30'\n",
    "start_date_l7 = '2000-01-01'\n",
    "end_date_l7 = '2022-12-31'\n",
    "start_date_l8 = '2013-04-01'\n",
    "end_date_l8 = '2022-12-31'\n",
    "\n",
    "with fiona.open('../example_data/pixel_centers_sm.gpkg') as layer:\n",
    "    minx, miny, maxx, maxy = layer.bounds\n",
    "    bbox = ee.Geometry.Rectangle([minx, miny, maxx, maxy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8632f74617c4d61d",
   "metadata": {},
   "source": [
    "Now, we can filter each landsat collection, process them to remove clouds, applying scaling factors for collection 2 surface reflectance (see https://developers.google.com/earth-engine/landsat_c1_to_c2 for details), and add an NDVI band. Then, we merge them, and sort by date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1491aa94fdc656a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T21:52:12.404322Z",
     "start_time": "2025-03-15T21:52:12.392732Z"
    }
   },
   "outputs": [],
   "source": [
    "# Landsat 5 collection\n",
    "collection_l5 = ee.ImageCollection(\"LANDSAT/LT05/C02/T1_L2\") \\\n",
    "    .filterDate(start_date_l5, end_date_l5) \\\n",
    "    .filterBounds(bbox) \\\n",
    "    .map(lambda image: cloudMaskL457(image, 'LANDSAT_5')) \\\n",
    "    .map(lambda image: scale_factors(image)) \\\n",
    "    .map(lambda image: addNDVI(image.set('SPACECRAFT_ID', 'LANDSAT_5')))\n",
    "\n",
    "# Landsat 7 collection\n",
    "collection_l7 = ee.ImageCollection(\"LANDSAT/LE07/C02/T1_L2\") \\\n",
    "    .filterDate(start_date_l7, end_date_l7) \\\n",
    "    .filterBounds(bbox) \\\n",
    "    .map(lambda image: cloudMaskL457(image, 'LANDSAT_7')) \\\n",
    "    .map(lambda image: scale_factors(image)) \\\n",
    "    .map(lambda image: addNDVI(image.set('SPACECRAFT_ID', 'LANDSAT_7')))\n",
    "\n",
    "# Landsat 8 collection\n",
    "collection_l8 = ee.ImageCollection(\"LANDSAT/LC08/C02/T1_L2\") \\\n",
    "    .filterDate(start_date_l8, end_date_l8) \\\n",
    "    .filterBounds(bbox) \\\n",
    "    .map(lambda image: cloudMaskL457(image, 'LANDSAT_8')) \\\n",
    "    .map(lambda image: scale_factors(image)) \\\n",
    "    .map(lambda image: addNDVI(image.set('SPACECRAFT_ID', 'LANDSAT_8')))\n",
    "\n",
    "# Merge collections\n",
    "merged_collection = ee.ImageCollection(collection_l5.merge(collection_l7).merge(collection_l8))\n",
    "\n",
    "# Sort the collection by date\n",
    "sorted_collection = merged_collection.sort('system:time_start')\n",
    "\n",
    "sorted_collection5 = collection_l5.sort('system:time_start')\n",
    "sorted_collection7 = collection_l7.sort('system:time_start')\n",
    "sorted_collection8 = collection_l8.sort('system:time_start')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba020b1c27de5fc3",
   "metadata": {},
   "source": [
    "Now we can create the time series data and save it locally. First, we will define a function to process the pixels (converted to points). This code is highly un-optimized and works for small regions but will take a very long time for large regions as it calls `getInfo()` on every loop. If doing this for a larger region, consider refactoring this to run this operation completely server-side on Google Earth Engine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fddbf375b3697ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T21:52:13.537598Z",
     "start_time": "2025-03-15T21:52:13.534969Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_poi(poi, sorted_collection):\n",
    "    reduce_to_point = create_reduce_region_function(\n",
    "        geometry=poi,\n",
    "        reducer=ee.Reducer.first(),\n",
    "        scale=30,\n",
    "        crs='EPSG:4326'\n",
    "    )\n",
    "    stat_fc = ee.FeatureCollection(\n",
    "        sorted_collection.map(\n",
    "            reduce_to_point\n",
    "        )\n",
    "    )\n",
    "    features = stat_fc.getInfo()['features']\n",
    "    lon, lat = poi.coordinates().getInfo()\n",
    "    data = []\n",
    "\n",
    "    for feature in features:\n",
    "        properties = feature['properties']\n",
    "        millis = properties.get('millis')\n",
    "        date = datetime.datetime.fromtimestamp(millis / 1000).strftime('%Y-%m-%d')\n",
    "        ndvi = properties.get('NDVI')\n",
    "        data.append((date, ndvi))\n",
    "\n",
    "    full_df = pd.DataFrame(data, columns=['Date', 'NDVI'])\n",
    "    full_df['Date'] = pd.to_datetime(full_df['Date'])\n",
    "    full_df = full_df.sort_values('Date')\n",
    "\n",
    "    ndvi_max = full_df.groupby(full_df['Date'].dt.strftime('%Y-%m'))['NDVI'].max().to_dict()\n",
    "\n",
    "    ndvi_max.update({'lon': lon, 'lat': lat})\n",
    "\n",
    "    return ndvi_max\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55fca3c54d2ffdb",
   "metadata": {},
   "source": [
    "Now, apply this to every mission collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3d480ff8b77797d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T21:59:44.260165Z",
     "start_time": "2025-03-15T21:52:26.312554Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [01:59<00:00,  1.09it/s]\n",
      "100%|██████████| 130/130 [03:01<00:00,  1.40s/it]\n",
      "100%|██████████| 130/130 [02:16<00:00,  1.05s/it]\n"
     ]
    }
   ],
   "source": [
    "pois = []\n",
    "with fiona.open('../example_data/pixel_centers_sm.gpkg') as layer:\n",
    "    for i, feature in enumerate(layer):\n",
    "        pnt = feature['geometry']['coordinates']\n",
    "        pois.append(ee.Geometry.Point(*pnt))\n",
    "\n",
    "for output, collection in [(\"landsat5_ndvi.csv\", sorted_collection5), (\"landsat7_ndvi.csv\", sorted_collection7), (\"landsat8_ndvi.csv\", sorted_collection8)]:\n",
    "    poi_args = [(poi, collection) for poi in pois]\n",
    "    results = []\n",
    "    for arg in tqdm(poi_args, total=len(pois)):\n",
    "        results.append(process_poi(*arg))\n",
    "\n",
    "    df_ndvi = pd.DataFrame(list(results))\n",
    "\n",
    "    df_ndvi.to_csv(output, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3479191adad002e7",
   "metadata": {},
   "source": [
    "You're done! Now you can harmonize this time series using the `harmonize` or `global_harmonize` module."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
